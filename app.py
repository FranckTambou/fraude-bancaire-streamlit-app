import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, roc_curve, auc

# --- Configuration de la page Streamlit ---
st.set_page_config(page_title="D√©tection de Fraude Bancaire", layout="wide", initial_sidebar_state="expanded")

# --- Titre de l'application ---
st.title("üõ°Ô∏è Application de D√©tection de Fraude Bancaire")
st.markdown("""
    Cette application permet de pr√©dire la probabilit√© de fraude pour des transactions bancaires.
    Veuillez entrer les d√©tails de la transaction ci-dessous.
""")

# --- Chargement des mod√®les et pr√©processeurs ---
@st.cache_data # Mise en cache pour √©viter de recharger √† chaque interaction
def load_assets():
    try:
        # Assurez-vous que ces chemins sont corrects si vos fichiers .pkl sont dans un sous-dossier
        # Pour l'upload GitHub simple, les fichiers .pkl doivent √™tre √† la racine du d√©p√¥t
        base_path = os.path.dirname(__file__) # Obtenir le chemin du r√©pertoire de l'app.py
        
        # Construire les chemins complets pour chaque fichier .pkl
        model_path = os.path.join(base_path, 'best_logistic_regression_model.pkl')
        scaler_path = os.path.join(base_path, 'scaler.pkl')
        ohe_path = os.path.join(base_path, 'one_hot_encoder.pkl')
        imputer_num_path = os.path.join(base_path, 'imputer_numeric.pkl')
        imputer_cat_path = os.path.join(base_path, 'imputer_categorical.pkl')
        feature_cols_path = os.path.join(base_path, 'feature_columns.pkl')

        best_logistic_regression_model = joblib.load(model_path)
        scaler = joblib.load(scaler_path)
        one_hot_encoder = joblib.load(ohe_path)
        imputer_numeric = joblib.load(imputer_num_path)
        imputer_categorical = joblib.load(imputer_cat_path)
        feature_columns = joblib.load(feature_cols_path)

        st.sidebar.success("Mod√®le et pr√©processeurs charg√©s avec succ√®s !")
        return best_logistic_regression_model, scaler, one_hot_encoder, imputer_numeric, imputer_categorical, feature_columns
    except FileNotFoundError as e:
        st.error(f"Erreur: Fichier manquant. Assurez-vous que tous les fichiers .pkl sont dans le m√™me r√©pertoire que app.py. D√©tail: {e}")
        st.info(f"Fichiers attendus: best_logistic_regression_model.pkl, scaler.pkl, one_hot_encoder.pkl, imputer_numeric.pkl, imputer_categorical.pkl, feature_columns.pkl")
        st.stop() # Arr√™te l'ex√©cution de l'application si les fichiers ne sont pas trouv√©s
    except Exception as e:
        st.error(f"Une erreur inattendue s'est produite lors du chargement des actifs: {e}")
        st.stop()

best_logistic_regression_model, scaler, one_hot_encoder, imputer_numeric, imputer_categorical, feature_columns = load_assets()

# --- D√©finition des colonnes num√©riques et cat√©gorielles pour l'input ---
numerical_cols = [
    'Amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest'
]
categorical_cols = [
    'Type'
]

# --- Interface utilisateur pour l'entr√©e des donn√©es ---
st.header("Saisie des d√©tails de la transaction")

# Input pour la colonne 'Type' (cat√©gorielle)
type_options = ['PAYMENT', 'TRANSFER', 'CASH_OUT', 'DEBIT', 'CASH_IN']
selected_type = st.selectbox("Type de transaction", type_options)

col1, col2, col3 = st.columns(3)
with col1:
    amount = st.number_input("Montant de la transaction", min_value=0.0, format="%.2f")
    oldbalanceOrg = st.number_input("Solde initial du compte d'origine", min_value=0.0, format="%.2f")
with col2:
    newbalanceOrig = st.number_input("Nouveau solde du compte d'origine", min_value=0.0, format="%.2f")
    oldbalanceDest = st.number_input("Solde initial du compte de destination", min_value=0.0, format="%.2f")
with col3:
    newbalanceDest = st.number_input("Nouveau solde du compte de destination", min_value=0.0, format="%.2f")

# Pr√©diction
if st.button("Pr√©dire la fraude"):
    # Cr√©ation du DataFrame d'entr√©e
    input_data = pd.DataFrame({
        'Type': [selected_type],
        'Amount': [amount],
        'oldbalanceOrg': [oldbalanceOrg],
        'newbalanceOrig': [newbalanceOrig],
        'oldbalanceDest': [oldbalanceDest],
        'newbalanceDest': [newbalanceDest]
    })

    # Imputation des valeurs manquantes (si le Imputer a des strat√©gies sp√©cifiques)
    # Pour l'imputation, nous devons s√©parer les colonnes num√©riques et cat√©gorielles si l'imputer √©tait entra√Æn√© comme √ßa
    input_numerical = input_data[numerical_cols]
    input_categorical = input_data[categorical_cols]

    # Appliquer l'imputation si les imputers ne sont pas None (v√©rifiez votre pipeline)
    if imputer_numeric:
        input_numerical_imputed = pd.DataFrame(imputer_numeric.transform(input_numerical), columns=numerical_cols, index=input_numerical.index)
    else:
        input_numerical_imputed = input_numerical # Pas d'imputation num√©rique si imputer_numeric est None
    
    if imputer_categorical:
        input_categorical_imputed = pd.DataFrame(imputer_categorical.transform(input_categorical), columns=categorical_cols, index=input_categorical.index)
    else:
        input_categorical_imputed = input_categorical # Pas d'imputation cat√©gorielle si imputer_categorical est None


    # One-Hot Encoding
    # Il est crucial que les colonnes soient dans le m√™me ordre que lors de l'entra√Ænement de l'OHE
    # Assurez-vous que l'OHE est entra√Æn√© sur toutes les cat√©gories possibles
    try:
        input_encoded = one_hot_encoder.transform(input_categorical_imputed)
        input_encoded_df = pd.DataFrame(input_encoded.toarray(), columns=one_hot_encoder.get_feature_names_out(categorical_cols), index=input_categorical_imputed.index)
    except Exception as e:
        st.error(f"Erreur lors de l'encodage One-Hot. Assurez-vous que toutes les cat√©gories possibles sont g√©r√©es : {e}")
        st.stop()


    # Concat√©nation des caract√©ristiques num√©riques et encod√©es
    # Assurez-vous que l'ordre des colonnes correspond √† feature_columns
    processed_data = pd.concat([input_numerical_imputed, input_encoded_df], axis=1)

    # R√©ordonnancement et alignement des colonnes avec feature_columns (tr√®s important)
    # Cr√©e un DataFrame vide avec les colonnes d'entra√Ænement, puis remplit avec les donn√©es trait√©es
    final_input = pd.DataFrame(columns=feature_columns)
    for col in feature_columns:
        if col in processed_data.columns:
            final_input[col] = processed_data[col]
        else:
            final_input[col] = 0 # Remplir avec 0 pour les colonnes manquantes (si une cat√©gorie n'est pas pr√©sente)
    
    # G√©rer les NaNs potentiels si une colonne num√©rique n'√©tait pas dans processed_data
    final_input = final_input.fillna(0) # ou une autre strat√©gie d'imputation si n√©cessaire

    # Scaling des caract√©ristiques num√©riques
    # Il est crucial d'appliquer le scaler uniquement aux colonnes num√©riques AVANT l'encodage
    # Ici, le scaling est appliqu√© apr√®s l'encodage et la concat√©nation,
    # il doit donc √™tre appliqu√© sur toutes les colonnes qui √©taient num√©riques √† l'origine.
    # On doit scaler les colonnes num√©riques dans final_input
    # Cr√©ons une copie pour le scaling afin de ne pas modifier l'original
    final_input_scaled = final_input.copy()
    
    # Appliquer le scaler uniquement aux colonnes num√©riques qui √©taient utilis√©es pour entra√Æner le scaler
    # Assurez-vous que 'numerical_cols' est la liste correcte des colonnes que le 'scaler' attend.
    final_input_scaled[numerical_cols] = scaler.transform(final_input_scaled[numerical_cols])

    # Pr√©diction de la probabilit√©
    prediction_proba = best_logistic_regression_model.predict_proba(final_input_scaled)[:, 1][0]
    
    # Interpr√©tation du r√©sultat
    st.subheader("R√©sultat de la pr√©diction :")
    if prediction_proba >= 0.5: # Seuil de 0.5 pour la d√©tection de fraude
        st.error(f"**Fraude d√©tect√©e !** Probabilit√© : {prediction_proba:.2%}")
        st.warning("Cette transaction pr√©sente une forte probabilit√© de fraude. Une v√©rification est recommand√©e.")
    else:
        st.success(f"**Non-fraude d√©tect√©e.** Probabilit√© : {prediction_proba:.2%}")
        st.info("Cette transaction semble l√©gitime.")

    st.markdown("---")
    st.subheader("D√©tails des donn√©es d'entr√©e trait√©es :")
    st.dataframe(final_input_scaled)

# --- Section d'information suppl√©mentaire (Sidebar) ---
st.sidebar.header("√Ä propos de l'application")
st.sidebar.info("""
    Cette application utilise un mod√®le de r√©gression logistique entra√Æn√© pour classifier
    les transactions bancaires comme frauduleuses ou non.
""")
st.sidebar.markdown("---")
st.sidebar.write("D√©velopp√© par [Votre Nom/Organisation]")
st.sidebar.write("Version : 1.0")

# --- Visualisation des m√©triques (si vous voulez ajouter des images statiques) ---
# Si vous avez des images de ROC, Confusion Matrix, etc., vous pouvez les afficher.
# Assurez-vous que les fichiers .png sont aussi dans votre d√©p√¥t GitHub.
st.markdown("---")
st.subheader("Performance du mod√®le (sur les donn√©es d'entra√Ænement/test) :")
st.write("Ces graphiques illustrent la performance du mod√®le lors de son entra√Ænement.")

# Exemple d'affichage d'images (remplacez par vos vrais chemins d'images)
try:
    # Assurez-vous que ces fichiers d'images sont pr√©sents dans le m√™me r√©pertoire que app.py sur GitHub
    img_dir = os.path.dirname(__file__)
    st.image(os.path.join(img_dir, "ROC.png"), caption="Courbe ROC", use_column_width=True)
    st.image(os.path.join(img_dir, "confusion.png"), caption="Matrice de Confusion", use_column_width=True)
except FileNotFoundError:
    st.warning("Les images de performance (ROC.png, confusion.png) n'ont pas √©t√© trouv√©es. Assurez-vous de les uploader sur GitHub.")
